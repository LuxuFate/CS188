# CS188: Introduction to Artificial Intelligence

CS188 introduces the basic ideas and techniques underlying the design of intelligent computer systems with a specific emphasis on the statistical and decision-theoretic modeling paradigm. By the end of the course, you will have built autonomous agents that efficiently make decisions in stochastic and in adversarial settings, drawn inferences in uncertain environments, optimized actions for arbitrary reward structures, and created machine learning algorithms.

I have built autonomous agents that efficiently make decisions in fully informed, partially observable, and adversarial settings. My agents draw inferences in uncertain environments and optimize actions for arbitrary reward structures. My machine learning algorithms will classify handwritten digits and photographs. The techniques in this course apply to a wide variety of artificial intelligence problems and will serve as the foundation for further study in any application area further pursued.

## **Important Links:**

[Course Website](https://inst.eecs.berkeley.edu/~cs188/sp22/) 

[Project 1: Search](https://inst.eecs.berkeley.edu/~cs188/sp22/project1/)

[Project 2: Multi-Agent Search](https://inst.eecs.berkeley.edu/~cs188/sp22/project2/)

[Project 3: Logic and Classical Planning](https://inst.eecs.berkeley.edu/~cs188/sp22/project3/)

[Project 4: Ghostbusters](https://inst.eecs.berkeley.edu/~cs188/sp22/project4/)

[Project 5: Machine Learning](https://inst.eecs.berkeley.edu/~cs188/sp22/project5/)

[Project 6: Reinforcement Learning](https://inst.eecs.berkeley.edu/~cs188/sp22/project6/)

## Topics Covered
* Search and Planning
* Uninformed Search (Depth-First, Breadth-First, Uniform-Cost)
* Informed Search (A*, Greedy Search)
* Heuristics and Optimality
* Constraint Satisfaction Problems
* Backtracking Search
* Constraint Propagation (Arc Consistency)
* Exploiting Graph Structure
* Game Trees and Tree-Structured Computation
* Minimax, Expectimax, Combinations
* Evaluation Functions and Approximations
* Alpha-Beta Pruning
* Decision Theory
* Preferences, Rationality, and Utilities
* Maximum Expected Utility
* Markov Decision Processes
* Policies, Rewards, and Values
* Value Iteration
* Policy Iteration
* Reinforcement Learning
* TD/Q Learning
* Exploration
* Approximation
* Application of Neural Nets (using TensorFlow)
